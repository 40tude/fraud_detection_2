{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# ! Select evidently_no_docker virtual env \n",
    "# conda install numpy pandas evidently  -c conda-forge -y just ins case\n",
    "# \n",
    "\n",
    "# In demo mode it generates biased production dataset \n",
    "k_DEMO_MODE = True\n",
    "\n",
    "# In debug mode it limit the umber of samples to be used to generate the report to speed up the process\n",
    "k_DEBUG_MODE = True\n",
    "\n",
    "\n",
    "# !!!!!!!!!!!!!!!!!\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# prelude\n",
    "\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "pd.options.display.max_columns = None\n",
    "# pd.reset_option('display.max_columns')\n",
    "\n",
    "# import evidently\n",
    "# print(evidently.__version__)\n",
    "\n",
    "from evidently.report import Report\n",
    "from evidently.test_suite import TestSuite\n",
    "from evidently.metric_preset import DataDriftPreset\n",
    "from evidently.test_preset import DataStabilityTestPreset\n",
    "from evidently.pipeline.column_mapping import ColumnMapping\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "k_Number_of_samples     = 512  # ! Must be an even number >= 62\n",
    "\n",
    "# k_Current_dir   = Path.cwd()\n",
    "# print(k_Current_dir)\n",
    "k_AssetsDir             = Path(\"../../04_data\")\n",
    "k_Local_Fraud_Test_csv  = \"fraud_test.csv\"\n",
    "k_URL_Fraud_Test_csv    = \"https://lead-program-assets.s3.eu-west-3.amazonaws.com/M05-Projects/fraudTest.csv\"\n",
    "\n",
    "k_Reference_Dataset_Dataset     = \"reference_sample.csv\"\n",
    "k_Production_Dataset_Dataset    = 'production_sample.csv'\n",
    "k_Production_Drifted_Dataset    = 'production_drifted_sample.csv'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>gender</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>dob</th>\n",
       "      <th>trans_num</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-06-21 12:14:25</td>\n",
       "      <td>2291163933867244</td>\n",
       "      <td>fraud_Kirlin and Sons</td>\n",
       "      <td>personal_care</td>\n",
       "      <td>2.86</td>\n",
       "      <td>Jeff</td>\n",
       "      <td>Elliott</td>\n",
       "      <td>M</td>\n",
       "      <td>351 Darlene Green</td>\n",
       "      <td>Columbia</td>\n",
       "      <td>SC</td>\n",
       "      <td>29209</td>\n",
       "      <td>33.9659</td>\n",
       "      <td>-80.9355</td>\n",
       "      <td>333497</td>\n",
       "      <td>Mechanical engineer</td>\n",
       "      <td>1968-03-19</td>\n",
       "      <td>2da90c7d74bd46a0caf3777415b3ebd3</td>\n",
       "      <td>1371816865</td>\n",
       "      <td>33.986391</td>\n",
       "      <td>-81.200714</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-06-21 12:14:33</td>\n",
       "      <td>3573030041201292</td>\n",
       "      <td>fraud_Sporer-Keebler</td>\n",
       "      <td>personal_care</td>\n",
       "      <td>29.84</td>\n",
       "      <td>Joanne</td>\n",
       "      <td>Williams</td>\n",
       "      <td>F</td>\n",
       "      <td>3638 Marsh Union</td>\n",
       "      <td>Altonah</td>\n",
       "      <td>UT</td>\n",
       "      <td>84002</td>\n",
       "      <td>40.3207</td>\n",
       "      <td>-110.4360</td>\n",
       "      <td>302</td>\n",
       "      <td>Sales professional, IT</td>\n",
       "      <td>1990-01-17</td>\n",
       "      <td>324cc204407e99f51b0d6ca0055005e7</td>\n",
       "      <td>1371816873</td>\n",
       "      <td>39.450498</td>\n",
       "      <td>-109.960431</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-06-21 12:14:53</td>\n",
       "      <td>3598215285024754</td>\n",
       "      <td>fraud_Swaniawski, Nitzsche and Welch</td>\n",
       "      <td>health_fitness</td>\n",
       "      <td>41.28</td>\n",
       "      <td>Ashley</td>\n",
       "      <td>Lopez</td>\n",
       "      <td>F</td>\n",
       "      <td>9333 Valentine Point</td>\n",
       "      <td>Bellmore</td>\n",
       "      <td>NY</td>\n",
       "      <td>11710</td>\n",
       "      <td>40.6729</td>\n",
       "      <td>-73.5365</td>\n",
       "      <td>34496</td>\n",
       "      <td>Librarian, public</td>\n",
       "      <td>1970-10-21</td>\n",
       "      <td>c81755dbbbea9d5c77f094348a7579be</td>\n",
       "      <td>1371816893</td>\n",
       "      <td>40.495810</td>\n",
       "      <td>-74.196111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id trans_date_trans_time            cc_num  \\\n",
       "0   0   2020-06-21 12:14:25  2291163933867244   \n",
       "1   1   2020-06-21 12:14:33  3573030041201292   \n",
       "2   2   2020-06-21 12:14:53  3598215285024754   \n",
       "\n",
       "                               merchant        category    amt   first  \\\n",
       "0                 fraud_Kirlin and Sons   personal_care   2.86    Jeff   \n",
       "1                  fraud_Sporer-Keebler   personal_care  29.84  Joanne   \n",
       "2  fraud_Swaniawski, Nitzsche and Welch  health_fitness  41.28  Ashley   \n",
       "\n",
       "       last gender                street      city state    zip      lat  \\\n",
       "0   Elliott      M     351 Darlene Green  Columbia    SC  29209  33.9659   \n",
       "1  Williams      F      3638 Marsh Union   Altonah    UT  84002  40.3207   \n",
       "2     Lopez      F  9333 Valentine Point  Bellmore    NY  11710  40.6729   \n",
       "\n",
       "       long  city_pop                     job         dob  \\\n",
       "0  -80.9355    333497     Mechanical engineer  1968-03-19   \n",
       "1 -110.4360       302  Sales professional, IT  1990-01-17   \n",
       "2  -73.5365     34496       Librarian, public  1970-10-21   \n",
       "\n",
       "                          trans_num   unix_time  merch_lat  merch_long  \\\n",
       "0  2da90c7d74bd46a0caf3777415b3ebd3  1371816865  33.986391  -81.200714   \n",
       "1  324cc204407e99f51b0d6ca0055005e7  1371816873  39.450498 -109.960431   \n",
       "2  c81755dbbbea9d5c77f094348a7579be  1371816893  40.495810  -74.196111   \n",
       "\n",
       "   is_fraud  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "df = pd.read_csv(k_AssetsDir/k_Local_Fraud_Test_csv)\n",
    "df.rename(columns={df.columns[0]: 'id'}, inplace=True)\n",
    "\n",
    "\n",
    "# Alternative (AWS S3 bucket)\n",
    "# df = pd.read_csv(k_URL_Fraud_Test_csv)\n",
    "\n",
    "df.columns = df.columns.str.lower()\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the dataset: 555719\n",
      "Saved reference sample to: ..\\..\\04_data\\reference_sample.csv\n",
      "Saved production sample to: ..\\..\\04_data\\production_sample.csv\n"
     ]
    }
   ],
   "source": [
    "def generate_datasets() -> None:\n",
    "    \"\"\"\n",
    "    Create two random samples if there are sufficient rows in the dataset.\n",
    "    \"\"\"\n",
    "    assert k_Number_of_samples%2==0 and k_Number_of_samples>=60\n",
    "    \n",
    "    # Define the data directory and file paths\n",
    "    # data_dir = Path('../../data')\n",
    "    fraud_test_file = Path(k_AssetsDir)/k_Local_Fraud_Test_csv\n",
    "    \n",
    "    # Check if the input file exists\n",
    "    if not fraud_test_file.exists():\n",
    "        print(f\"File not found: {fraud_test_file}\")\n",
    "        return\n",
    "\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(fraud_test_file)\n",
    "\n",
    "    # Determine the number of rows\n",
    "    num_rows: int = len(df)\n",
    "    print(f\"Number of rows in the dataset: {num_rows}\")\n",
    "\n",
    "    # Stop if there are less than 2000 rows\n",
    "    # Indeed I want 1_000 in one set and 1_000 others rows in the other set\n",
    "    if num_rows < k_Number_of_samples:\n",
    "        print(\"Not enough rows in the dataset. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Take 1_000 random rows for the reference sample\n",
    "    reference_indices = random.sample(range(num_rows), int(k_Number_of_samples/2))\n",
    "    reference_df = df.iloc[reference_indices]\n",
    "\n",
    "    # Take another 1_000 random rows for the production sample (different from the first set)\n",
    "    remaining_indices = list(set(range(num_rows)) - set(reference_indices))\n",
    "    production_indices = random.sample(remaining_indices, int(k_Number_of_samples/2))\n",
    "    production_df = df.iloc[production_indices]\n",
    "\n",
    "    # Save the samples to their respective files\n",
    "    reference_sample_file = Path(k_AssetsDir) / k_Reference_Dataset_Dataset\n",
    "    production_sample_file = Path(k_AssetsDir) / k_Production_Dataset_Dataset \n",
    "    reference_df.to_csv(reference_sample_file, index=False)\n",
    "    production_df.to_csv(production_sample_file, index=False)\n",
    "\n",
    "    print(f\"Saved reference sample to: {reference_sample_file}\")\n",
    "    print(f\"Saved production sample to: {production_sample_file}\")\n",
    "\n",
    "generate_datasets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_df = pd.read_csv(Path(k_AssetsDir) / k_Reference_Dataset_Dataset)\n",
    "reference_df.rename(columns={reference_df.columns[0]: 'id'}, inplace=True)\n",
    "reference_df[\"trans_date_trans_time\"] = pd.to_datetime(reference_df[\"trans_date_trans_time\"], format='%Y-%m-%d %H:%M:%S')\n",
    "reference_df[\"dob\"] = pd.to_datetime(reference_df[\"dob\"], format='%Y-%m-%d')\n",
    "reference_df[\"is_fraud\"] = reference_df[\"is_fraud\"].astype(bool)\n",
    "\n",
    "\n",
    "production_df = pd.read_csv(Path(k_AssetsDir) / k_Production_Dataset_Dataset)\n",
    "production_df.rename(columns={production_df.columns[0]: 'id'}, inplace=True)\n",
    "production_df[\"trans_date_trans_time\"] = pd.to_datetime(production_df[\"trans_date_trans_time\"], format='%Y-%m-%d %H:%M:%S')\n",
    "production_df[\"dob\"] = pd.to_datetime(production_df[\"dob\"], format='%Y-%m-%d')\n",
    "production_df[\"is_fraud\"] = production_df[\"is_fraud\"].astype(bool)\n",
    "\n",
    "\n",
    "# print(reference_df.dtypes)\n",
    "# display(reference_df.head(5))\n",
    "# Afficher les 5 premières lignes du DataFrame filtré \n",
    "# Histoire de se rassurer\n",
    "# filtered_df = df[df['is_fraud'] == 1] \n",
    "# filtered_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference_df.describe(include='all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Summary statistics for 'amt' in reference data:\")\n",
    "# print(reference_df['amt'].describe())\n",
    "# print(\"\\nSummary statistics for 'amt' in production drifted data:\")\n",
    "# print(production_df['amt'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Montants (amt) : 30 % des transactions ont été augmentées de 50 %.\n",
    "# Latitudes et longitudes (merch_lat, merch_long) : 20 % des transactions ont subi un décalage.\n",
    "# Catégories (category) : 30 % des transactions ont vu leur catégorie changée en faveur d'un biais.\n",
    "def bias_production_dataset(production_df):\n",
    "\n",
    "    # Créer une copie des données pour introduire un drift\n",
    "    production_drifted_df = production_df.copy()\n",
    "\n",
    "    # np.random.choice([1, 2.0], size=len(production_df), p=[0.7, 0.3]) :\n",
    "    # Génère un tableau de taille production_drifted_df['amt'] \n",
    "    # Chaque élément vaut 1 ou 2 \n",
    "    # Probabilités associées :\n",
    "    # 70 % des valeurs générées seront 1.\n",
    "    # 30 % des valeurs générées seront 2 \n",
    "    # Du coup 30% des valeurs auront été mult par 2 => Normalement ca doit drifter !!!\n",
    "    production_drifted_df['amt'] = production_drifted_df['amt'] * np.random.choice([1.0, 2.0], size=len(production_df), p=[0.2, 0.8]) # p=[0.7, 0.3]\n",
    "\n",
    "    # Drift 2: Modifier les latitudes et longitudes ('merch_lat', 'merch_long')\n",
    "    # Introduire un décalage artificiel pour certaines transactions\n",
    "    # ! INUTILE car les transaction sont sur tout le pays\n",
    "    # production_drifted_df['merch_lat'] += np.random.choice([0, 0.1], size=len(production_df), p=[0.6, 0.4])\n",
    "    # production_drifted_df['merch_long'] += np.random.choice([0, -0.1], size=len(production_df), p=[0.6, 0.4])\n",
    "\n",
    "    # Drift 3: Modifier la répartition des catégories ('category')\n",
    "    # Introduire un biais pour favoriser certaines catégories\n",
    "    categories = production_drifted_df['category'].unique()\n",
    "    biased_categories = np.random.choice(categories, size=len(production_df), p=[0.5] + [0.5 / (len(categories) - 1)] * (len(categories) - 1))\n",
    "\n",
    "    # Modifier les catégories avec une probabilité de 30%\n",
    "    production_drifted_df['category'] = np.where(\n",
    "        np.random.rand(len(production_df)) < 0.3,  # 30% des lignes seront modifiées\n",
    "        biased_categories,  # Nouvelle catégorie biaisée\n",
    "        production_drifted_df['category']  # Catégorie actuelle\n",
    "    )\n",
    "\n",
    "    # Enregistrer le dataset drifté pour les tests\n",
    "    production_drifted_df.to_csv(Path(k_AssetsDir)/k_Production_Drifted_Dataset, index=False)\n",
    "\n",
    "\n",
    "\n",
    "    # print(reference_df.dtypes)\n",
    "    # display(reference_df.head(5))\n",
    "    # production_drifted_df.describe(include='all')\n",
    "    return (production_drifted_df)\n",
    "\n",
    "if(k_DEMO_MODE):\n",
    "    production_df = bias_production_dataset(production_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Summary statistics for 'amt' in reference data:\")\n",
    "# print(reference_df['amt'].describe())\n",
    "# print(\"\\nSummary statistics for 'amt' in production drifted data:\")\n",
    "# print(production_drifted_df['amt'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer uniquement les colonnes numériques dans les DataFrames\n",
    "# Car le modèle n'utilise que les données numériques et qu'en plus en mode demo\n",
    "# on introduit du biais que sur certaines données numériques\n",
    "\n",
    "reference_numeric_df  = reference_df.select_dtypes(include=\"number\")\n",
    "production_numeric_df = production_df.select_dtypes(include=\"number\")\n",
    "# production_drifted_numeric_df = production_drifted_df.select_dtypes(include=\"number\")\n",
    "\n",
    "numeric_columns = reference_df.select_dtypes(include=\"number\").columns\n",
    "object_columns = reference_df.select_dtypes(include=\"object\").columns\n",
    "\n",
    "\n",
    "column_mapping = ColumnMapping(\n",
    "    numerical_features=numeric_columns,\n",
    "    # categorical_features=[\"gender\", \"category\"],\n",
    "    datetime_features=[\"trans_date_trans_time\", \"dob\"],\n",
    "    target=\"is_fraud\",\n",
    "    id=\"id\"\n",
    ")\n",
    "\n",
    "\n",
    "# Run the report and analyze drift\n",
    "data_drift_report = Report(metrics=[DataDriftPreset()])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with drift: ['amt']\n"
     ]
    }
   ],
   "source": [
    "data_drift_report.run(reference_data=reference_numeric_df, current_data=production_numeric_df)\n",
    "\n",
    "# Extract and display drifted features\n",
    "results = data_drift_report.as_dict()\n",
    "drift_by_columns = results['metrics'][1]['result']['drift_by_columns']\n",
    "\n",
    "# Display features with drift\n",
    "drifted_features = [\n",
    "    col for col, details in drift_by_columns.items()\n",
    "    # Si la clé 'drift_detected' existe dans le dictionnaire, sa valeur sera retournée sinon on retourne False\n",
    "    if details.get('drift_detected', False)  \n",
    "]\n",
    "print(\"Features with drift:\", drifted_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # Run the report and analyze drift\n",
    "    data_drift_report.run(reference_data=reference_numeric_df, current_data=production_drifted_numeric_df)\n",
    "\n",
    "    # Extract and display drifted features\n",
    "    results = data_drift_report.as_dict()\n",
    "    drift_by_columns = results['metrics'][1]['result']['drift_by_columns']\n",
    "\n",
    "    # Display features with drift\n",
    "    drifted_features = [\n",
    "        col for col, details in drift_by_columns.items()\n",
    "        # Si la clé 'drift_detected' existe dans le dictionnaire, sa valeur sera retournée sinon on retourne False\n",
    "        if details.get('drift_detected', False)  \n",
    "    ]\n",
    "    print(\"Features with drift:\", drifted_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column_mapping=None => Inférence automatique\n",
    "data_drift_report.run(reference_data=reference_numeric_df, current_data=production_numeric_df, column_mapping=None)\n",
    "data_drift_report.show(\"inline\")\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_file = f\"data_drift_report_{timestamp}.html\"\n",
    "data_drift_report.save_html(output_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    data_stability= TestSuite(tests=[\n",
    "        DataStabilityTestPreset(), # ici on fait 1 seul test de stabilité\n",
    "    ])\n",
    "\n",
    "    # column_mapping=None => Inférence automatique\n",
    "    data_stability.run(reference_data=reference_numeric_df, current_data=production_numeric_df, column_mapping=None)         \n",
    "    data_stability.show(\"inline\")\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_file = f\"data_stability_report_{timestamp}.html\"\n",
    "    data_drift_report.save_html(output_file)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evidently_no_docker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
